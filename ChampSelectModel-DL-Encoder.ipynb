{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "from keras.layers import LSTM,Dense,Dropout,BatchNormalization,LayerNormalization, InputLayer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the processed data\n",
    "All_Games = pd.read_csv(\"All_Matches.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the categorical columns\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoder_df = pd.DataFrame(encoder.fit_transform(All_Games[[\"Rank\",\"Top_Current_Champ\", \"Jg_Current_Champ\", \"Mid_Current_Champ\", \"Bot_Current_Champ\", \"Sup_Current_Champ\",\"Top_Enemy_Champ\", \"Jg_Enemy_Champ\", \"Mid_Enemy_Champ\", \"Bot_Enemy_Champ\", \"Sup_Enemy_Champ\"]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the categorical columns and join the one hot encoded version\n",
    "\n",
    "All_Games = All_Games.drop([\"Rank\",\"Top_Current_Champ\", \"Jg_Current_Champ\", \"Mid_Current_Champ\", \"Bot_Current_Champ\", \"Sup_Current_Champ\",\"Top_Enemy_Champ\", \"Jg_Enemy_Champ\", \"Mid_Enemy_Champ\", \"Bot_Enemy_Champ\", \"Sup_Enemy_Champ\"],axis=1)\n",
    "All_Games = pd.DataFrame(np.hstack([All_Games, encoder_df]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All_Games = shuffle(All_Games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = All_Games.iloc[:,1:]\n",
    "y = All_Games.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ratio = 0.80\n",
    "# test_ratio = 0.10\n",
    "# validation_ratio = 0.10\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=test_ratio)\n",
    "\n",
    "# X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=validation_ratio/(train_ratio+test_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, y, test_size=.20, shuffle=True,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the 80-20 to 80-10-10\n",
    "\n",
    "SplitX = X_valid\n",
    "SplitY = Y_valid\n",
    "\n",
    "X_valid = SplitX.iloc[:1500]\n",
    "Y_valid = SplitY.iloc[:1500]\n",
    "\n",
    "X_test = SplitX.iloc[1500:]\n",
    "Y_test = SplitY.iloc[1500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the data using minmax\n",
    "\n",
    "sc = MinMaxScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_valid = sc.transform(X_valid)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model\n",
    "\n",
    "model_one_hot = keras.Sequential() \n",
    "\n",
    "model_one_hot.add(InputLayer(input_shape=X_train.shape[1]))\n",
    "model_one_hot.add(Dense(128, activation='relu'))  \n",
    "\n",
    "model_one_hot.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model_one_hot.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), metrics=['acc'])\n",
    "\n",
    "model_one_hot.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping\n",
    "\n",
    "es = EarlyStopping(monitor='val_acc', mode='max', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit with early stopping\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    fit_model_one_hot = model_one_hot.fit(X_train, Y_train, validation_data=(X_valid,Y_valid), epochs=250, callbacks=es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print loss and score on testing\n",
    "\n",
    "score = model_one_hot.evaluate(X_test, Y_test,verbose=0)\n",
    "#score = model_one_hot.evaluate(X_valid, Y_valid,verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "\n",
    "model_one_hot.save(\"KerasModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plit graphs\n",
    "\n",
    "plt.plot(fit_model_one_hot.history['acc'])\n",
    "plt.plot(fit_model_one_hot.history['val_acc'])\n",
    "plt.legend(['accuracy','validation accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the scaler and encoder to be used to for predictions later on the website\n",
    "\n",
    "joblib.dump(sc, 'MinMaxScaler.gz')\n",
    "joblib.dump(encoder,'OneHotEncoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the scaler and encdoer and transform the prediction dataframe/csv\n",
    "# modified in the website file\n",
    "\n",
    "def ProcessLiveData(data):\n",
    "    min_max_scaler = joblib.load('MinMaxScaler.gz')\n",
    "    one_hot_encoder = joblib.load('OneHotEncoder.joblib')\n",
    "    encoder_lobby = pd.DataFrame(one_hot_encoder.transform(data[[\"Rank\",\"Top_Current_Champ\", \"Jg_Current_Champ\", \"Mid_Current_Champ\", \"Bot_Current_Champ\", \"Sup_Current_Champ\",\"Top_Enemy_Champ\", \"Jg_Enemy_Champ\", \"Mid_Enemy_Champ\", \"Bot_Enemy_Champ\", \"Sup_Enemy_Champ\"]]).toarray())\n",
    "    data = data.join(encoder_lobby)\n",
    "    data = data.drop([\"Rank\",\"Top_Current_Champ\", \"Jg_Current_Champ\", \"Mid_Current_Champ\", \"Bot_Current_Champ\", \"Sup_Current_Champ\",\"Top_Enemy_Champ\", \"Jg_Enemy_Champ\", \"Mid_Enemy_Champ\", \"Bot_Enemy_Champ\", \"Sup_Enemy_Champ\"],axis=1)\n",
    "    data[\"Side\"] = data[\"Side\"].astype('category')\n",
    "    data[\"Side\"] = data[\"Side\"].cat.codes\n",
    "    data = min_max_scaler.transform(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model call the process data function and then use that to output a prediction\n",
    "\n",
    "def Predict():\n",
    "    model = load_model('KerasModel.h5')\n",
    "    lobby =  pd.read_csv(\"lobby.csv\")\n",
    "    NewPredict = ProcessLiveData(lobby)\n",
    "    return model.predict(NewPredict)[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holds the prediction\n",
    "\n",
    "prediction = Predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the prediction\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train multiple times\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for i in range(15):\n",
    "    \n",
    "    model_one_hot = keras.Sequential() \n",
    "    model_one_hot.add(InputLayer(input_shape=X_train.shape[1]))\n",
    "    model_one_hot.add(Dense(128, activation='relu'))  \n",
    "    model_one_hot.add(Dense(1, activation='sigmoid')) \n",
    "    model_one_hot.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), metrics=['acc'])\n",
    "\n",
    "    fit_model_one_hot = model_one_hot.fit(X_train, Y_train, validation_data=(X_valid,Y_valid), epochs=250, callbacks=es)\n",
    "    score = model_one_hot.evaluate(X_test, Y_test,verbose=0)\n",
    "    accuracies.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean and standard deviation\n",
    "\n",
    "accuracies_percent = [element * 100 for element in accuracies]\n",
    "\n",
    "print(\"The original list : \" + str(accuracies_percent))\n",
    "print(\"mean : \",sum(accuracies_percent) / len(accuracies_percent))\n",
    "# Standard deviation of list\n",
    "# Using sum() + list comprehension\n",
    "mean = sum(accuracies_percent) / len(accuracies_percent)\n",
    "variance = sum([((x - mean) ** 2) for x in accuracies_percent]) / len(accuracies_percent)\n",
    "res = variance ** 0.5\n",
    "  \n",
    "# Printing result\n",
    "print(\"Standard deviation of sample is : \" + str(res))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c3a690832072b0bb6efc7c42b10bb68f5f79b08d22612911495608130451ffe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
